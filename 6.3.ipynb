{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.3.1\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def custom_batch_norm1d(input_tensor, eps):\n",
    "    var = torch.var(input_tensor,0, unbiased = False)\n",
    "    mn = torch.mean(input_tensor,0)\n",
    "\n",
    "    normed_tensor=(input_tensor - mn)/torch.sqrt((var+eps))\n",
    "    return normed_tensor\n",
    "\n",
    "\n",
    "input_tensor = torch.Tensor([[0.0, 0, 1, 0, 2], [0, 1, 1, 0, 10]])\n",
    "batch_norm = nn.BatchNorm1d(input_tensor.shape[1], affine=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "all_correct = True\n",
    "for eps_power in range(10):\n",
    "    eps = np.power(10., -eps_power)\n",
    "    batch_norm.eps = eps\n",
    "    batch_norm_out = batch_norm(input_tensor)\n",
    "    custom_batch_norm_out = custom_batch_norm1d(input_tensor, eps)\n",
    "\n",
    "\n",
    "all_correct &= torch.allclose(batch_norm_out, custom_batch_norm_out)\n",
    "all_correct &= batch_norm_out.shape == custom_batch_norm_out.shape\n",
    "print(all_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.3.2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_size = 7\n",
    "batch_size = 5\n",
    "input_tensor = torch.randn(batch_size, input_size, dtype=torch.float)\n",
    "\n",
    "eps = 1e-3\n",
    "\n",
    "def custom_batch_norm1d(input_tensor, weight, bias, eps):\n",
    "    var = torch.var(input_tensor,0, unbiased = False)\n",
    "    mn = torch.mean(input_tensor,0)\n",
    "\n",
    "    gamma = weight\n",
    "    betta = bias\n",
    "    \n",
    "    normed_tensor=((input_tensor - mn)/torch.sqrt((var+eps)))*gamma+betta\n",
    "   \n",
    "    return normed_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "batch_norm = nn.BatchNorm1d(input_size, eps=eps)\n",
    "batch_norm.bias.data = torch.randn(input_size, dtype=torch.float)\n",
    "batch_norm.weight.data = torch.randn(input_size, dtype=torch.float)\n",
    "batch_norm_out = batch_norm(input_tensor)\n",
    "custom_batch_norm_out = custom_batch_norm1d(input_tensor, batch_norm.weight.data, batch_norm.bias.data, eps)\n",
    "print(torch.allclose(batch_norm_out, custom_batch_norm_out) \\\n",
    "      and batch_norm_out.shape == custom_batch_norm_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.3.3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_size = 3\n",
    "batch_size = 5\n",
    "eps = 1e-1\n",
    "\n",
    "#Расчёт дисперсии ведётся по смещенной выборке (std)\n",
    "#Расчёт скользящего среднего по несмещенной\n",
    "class CustomBatchNorm1d:\n",
    "    def __init__(self, weight, bias, eps, momentum):\n",
    "        self.weight = weight #gamma\n",
    "        self.bias = bias     #betta\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = False\n",
    "        #дисперсия \n",
    "        self.var = 0\n",
    "        self.running_var = 1\n",
    "        #среднее \n",
    "        self.mn = 0\n",
    "        self.running_mean = 0\n",
    "        \n",
    "    def __call__(self, x):#x - input tenzor\n",
    "        normed_tensor = x\n",
    "        #если вызван .eval\n",
    "        if(self.training == True):\n",
    "            \n",
    "       \n",
    "            \n",
    "            #расчет скользящего среднего\n",
    "            self.mn = torch.mean(x,0)\n",
    "            self.running_mean = (1 - self.momentum)*self.running_mean + self.momentum * self.mn \n",
    "         \n",
    "            #расчет дисперсии \n",
    "            self.var = torch.var(x,0, unbiased = False)\n",
    "            self.running_var =  (1 - self.momentum) * self.running_mean + self.mn * momentum\n",
    "            \n",
    "            \n",
    "           # self.var = torch.var(x,0, unbiased = True)\n",
    "           # self.running_var = self.momentum * self.running_var + (1 - self.momentum) * self.var\n",
    "           # self.running_mean = self.momentum * self.running_mean + (1 - self.momentum) * self.mn\n",
    "            \n",
    "                   \n",
    "            self.training = False\n",
    "            \n",
    "        else:\n",
    "            tmp =(x - self.running_mean)/(torch.sqrt(self.running_var + self.eps))\n",
    "            normed_tensor = tmp *self.weight + self.bias\n",
    "            \n",
    "        return normed_tensor\n",
    "    def eval(self):\n",
    "        self.training = True\n",
    "\n",
    "batch_norm = nn.BatchNorm1d(input_size, eps=eps)\n",
    "batch_norm.bias.data = torch.randn(input_size, dtype=torch.float)\n",
    "batch_norm.weight.data = torch.randn(input_size, dtype=torch.float)\n",
    "batch_norm.momentum = 0.5\n",
    "\n",
    "custom_batch_norm1d = CustomBatchNorm1d(batch_norm.weight.data,\n",
    "                                        batch_norm.bias.data, eps, batch_norm.momentum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sqrt(): argument 'input' (position 1) must be Tensor, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-76901a3448ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtorch_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnorm_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcustom_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_batch_norm1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mall_correct\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mnorm_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcustom_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-191-ef9412a607ed>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mnormed_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sqrt(): argument 'input' (position 1) must be Tensor, not float"
     ]
    }
   ],
   "source": [
    "all_correct = True\n",
    "\n",
    "for i in range(8):\n",
    "    torch_input = torch.randn(batch_size, input_size, dtype=torch.float)\n",
    "    norm_output = batch_norm(torch_input)\n",
    "    custom_output = custom_batch_norm1d(torch_input)\n",
    "    all_correct &= torch.allclose(norm_output, custom_output) \\\n",
    "        and norm_output.shape == custom_output.shape\n",
    "\n",
    "batch_norm.eval()\n",
    "custom_batch_norm1d.eval()\n",
    "\n",
    "for i in range(8):\n",
    "    torch_input = torch.randn(batch_size, input_size, dtype=torch.float)\n",
    "    norm_output = batch_norm(torch_input)\n",
    "    custom_output = custom_batch_norm1d(torch_input)\n",
    "    all_correct &= torch.allclose(norm_output, custom_output) \\\n",
    "        and norm_output.shape == custom_output.shape\n",
    "print('#MEANS')\n",
    "print(batch_norm.running_mean)\n",
    "print(custom_batch_norm1d.running_mean)\n",
    "print('\\n#VARS')\n",
    "print(batch_norm.running_var)\n",
    "print(custom_batch_norm1d.running_var)\n",
    "print('\\n#OUTPUTS')\n",
    "print(norm_output)\n",
    "print(custom_output)\n",
    "print('\\n#RESULT')\n",
    "print(all_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w4 0.43614538244454387\n",
      "w3 0.30412468309754653\n",
      "w2 0.1677068587693903\n",
      "w1 0.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "print('w4',(1 - math.tanh(math.tanh(math.tanh(math.tanh(100))))**2)*math.tanh(math.tanh(math.tanh(100))))\n",
    "print('w3',(1 - math.tanh(math.tanh(math.tanh(math.tanh(100))))**2)*(1-math.tanh(math.tanh(math.tanh(100)))**2)*math.tanh(math.tanh(100)))\n",
    "print('w2',(1 - math.tanh(math.tanh(math.tanh(math.tanh(100))))**2)*(1-math.tanh(math.tanh(math.tanh(100)))**2)*(1-math.tanh(math.tanh(100))**2)*math.tanh(100))\n",
    "print('w1',(1 - math.tanh(math.tanh(math.tanh(math.tanh(100))))**2)*(1 - math.tanh(math.tanh(math.tanh(100)))**2)*(1 - math.tanh(math.tanh(100))**2)*(1 - math.tanh(100)**2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
